{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18631c9a",
   "metadata": {},
   "source": [
    "# Wild Fire Machine Learning (WFML) Utilities\n",
    "\n",
    "This class is used to gather helper functionalities and common data across all implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0bb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import subprocess\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve, roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1c097",
   "metadata": {},
   "source": [
    "## Static Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34ead23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wfml:\n",
    "    path = {\n",
    "      'root'  : 'C:/Users/gmano/Desktop/HOU/ΠΛΣΔΕ/ΔΕ/2. Υλοποίηση/model/',\n",
    "      'image' : 'image/',\n",
    "      'data'  : { 'root'  : 'data/',\n",
    "                  'tune'  : 'fire_data_tune/',\n",
    "                  'train' : 'fire_data_train/',\n",
    "                  'test'  : 'fire_data_test/' }\n",
    "    }\n",
    "\n",
    "    filename = {\n",
    "        'image' : '@@.png',\n",
    "        'tune'  : 'random_search_@@.csv',\n",
    "        'train' : 'fire_data_train.csv',\n",
    "        'test'  : '202007@@_df_greece_norm.csv'\n",
    "    }\n",
    "\n",
    "    features = ['dom_vel', 'dom_dir', 'max_temp', 'min_temp',\n",
    "                'mean_temp', 'rain_7_days', 'ndvi', 'lst_day', 'slope', 'dem',\n",
    "                'corine_gr1', 'corine_gr4', 'corine_gr5', 'corine_gr21', 'corine_gr22',\n",
    "                'corine_gr23', 'corine_gr24', 'corine_gr31', 'corine_gr32',\n",
    "                'corine_gr33']\n",
    "    \n",
    "    target = 'fire'\n",
    "\n",
    "    grouper = 'firedate' #Not the fish :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e84901",
   "metadata": {},
   "source": [
    "## File Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c705fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def get_path(path):\n",
    "        if  path == 'tune' or path == 'train' or path == 'test':\n",
    "            fullpath = __class__.path['root'] + __class__.path['data']['root'] + __class__.path['data'][path]\n",
    "        else:\n",
    "            fullpath = __class__.path['root'] + __class__.path[path]\n",
    "        return fullpath\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filepath(storage, replace = '@@', stamp = False):\n",
    "        path = __class__.get_path(storage) + __class__.filename[storage]\n",
    "\n",
    "        if storage == 'tune' or storage == 'image':\n",
    "            if stamp == True:\n",
    "                replace = replace + '_' + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            final = path.replace('@@', replace)\n",
    "        elif storage == 'test':\n",
    "            final = path.replace('@@', str(replace).zfill(2))\n",
    "        else:\n",
    "            final = path\n",
    "        return final\n",
    "      \n",
    "    @staticmethod\n",
    "    def get_filepaths(storage):\n",
    "        path = __class__.get_path(storage)\n",
    "        file = __class__.filename[storage]\n",
    "        \n",
    "        filepaths = [path+f for f in listdir(path) if bool(re.search(file.replace('@@', '[0-9][0-9]'), f)) == True]\n",
    "\n",
    "        return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd78511",
   "metadata": {},
   "source": [
    "## String Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9444efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def gini_to_alpha(gini):\n",
    "        # Gini to Numerical Alpha\n",
    "        if gini == '':\n",
    "            alpha = 0\n",
    "        else:\n",
    "            alpha = 1 - 2 * float(gini) #less gini = less transparency\n",
    "\n",
    "        # Scale the float to an integer (0-255)\n",
    "        if alpha < 0.0:\n",
    "            alpha = 0.0\n",
    "        elif alpha > 1.0:\n",
    "            alpha = 1.0\n",
    "\n",
    "        # Convert to hexadecimal and ensure it's two digits\n",
    "        hex_value = format(int(alpha * 255), '02x')\n",
    "\n",
    "        return hex_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa4b9e",
   "metadata": {},
   "source": [
    "## ML Utilities\n",
    "### Cross Validation Method\n",
    "This method performs the Cross Validation procedure with the RandomizedSearchCV optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3beeb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def cross_validation(base_model, parameters, kfold, X, y, groups, n_jobs = 2):\n",
    "        start_time = time.time()\n",
    "        unique_groups = np.unique(groups)\n",
    "\n",
    "        # Check if the number of unique groups is less than the number of folds required for cross-validation and\n",
    "        # raise error if there are not enough unique groups to perform the desired number of splits\n",
    "        if len(unique_groups) < kfold:\n",
    "            raise ValueError(f\"Number of splits {kfold} > number of unique groups {len(unique_groups)}.\")\n",
    "\n",
    "        # Initialize the StratifiedKFold object for cross-validation\n",
    "        k = StratifiedKFold(n_splits = kfold, shuffle=False)\n",
    "\n",
    "        # Define the metrics to be used for scoring the model during cross-validation\n",
    "        metrics = {'prec_1': make_scorer(precision_score, pos_label=1),\n",
    "                   'rec_1': make_scorer(recall_score, pos_label=1),\n",
    "                   'f1_1': make_scorer(f1_score, pos_label=1),\n",
    "                   'roc': make_scorer(roc_auc_score),\n",
    "                   'prec_0': make_scorer(precision_score, pos_label=0),\n",
    "                   'rec_0': make_scorer(recall_score, pos_label=0),\n",
    "                   'f1_0': make_scorer(f1_score, pos_label=0)}\n",
    "\n",
    "        # Initialize the RandomizedSearchCV object for hyperparameter tuning and model selection\n",
    "        optimal_model = RandomizedSearchCV(base_model,\n",
    "                                           parameters,\n",
    "                                           scoring = metrics,\n",
    "                                           n_iter = kfold, #Itterations same as kfold for square cross-validation space\n",
    "                                           cv = k,\n",
    "                                           n_jobs = n_jobs,\n",
    "                                           verbose = 3,\n",
    "                                           refit = 'rec_1',\n",
    "                                           return_train_score = True)\n",
    "\n",
    "        # Fit the model to the data using the specified groups for cross-validation\n",
    "        optimal_model.fit(X, y, groups=groups)\n",
    "\n",
    "        stop_time = time.time()\n",
    "        print(\"Elapsed Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time)))\n",
    "        print(\"====================\")\n",
    "        print(\"Best Score: {:.3f}\".format(optimal_model.best_score_))\n",
    "        print(\"Best Parameters: {}\".format(optimal_model.best_params_))\n",
    "        return optimal_model.best_params_, optimal_model.best_score_, optimal_model.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cefa0",
   "metadata": {},
   "source": [
    "### Hyperparameter Tune Method\n",
    "This method performs the actual hyperparameter tuning: loads train data, prepares CV attributes, rus CV utility, gathers and saves results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ff47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def hyperparameter_tune(n_jobs, classifier, cv_dimensions, parameters):\n",
    "        #Read Training File\n",
    "        df = pd.read_csv(wfml.get_filepath('train'))\n",
    "        df.firedate = pd.to_datetime(df.firedate)\n",
    "\n",
    "        # Ensure that groups have multiple unique values\n",
    "        if df[wfml.grouper].nunique() < 10:\n",
    "            df[wfml.grouper] = pd.cut(df[wfml.grouper].astype(int) // 10**9, bins=10, labels=False)\n",
    "\n",
    "        #Define Features & Target Variable\n",
    "        X = df[wfml.features]\n",
    "        y = df[wfml.target]\n",
    "\n",
    "        # Prepare the Split for Cross Validation\n",
    "        groups = df[wfml.grouper]\n",
    "        groupskfold = groups.values\n",
    "        folds = cv_dimensions\n",
    "\n",
    "        #Initialize arrays to gather results\n",
    "        best_scores = []\n",
    "        best_parameters = []\n",
    "        full_scores = []\n",
    "\n",
    "        #Define Model\n",
    "        if classifier == \"XGB\":\n",
    "            model = XGBClassifier( n_jobs = n_jobs )\n",
    "        elif classifier == \"RF\":\n",
    "            model = RandomForestClassifier( n_jobs = n_jobs )\n",
    "        else:\n",
    "            raise ValueError(\"Classifier not defined\")\n",
    "        \n",
    "        #Run for each of the defined k-folds\n",
    "        for i in folds:\n",
    "            print(\"\\ncv = \", i)\n",
    "            start = time.time() #Time Measurement is important here as it can be a long procedure\n",
    "\n",
    "            try:\n",
    "                best_params, best_score, full_scores = __class__.cross_validation(model, parameters, i, X, y, groupskfold, n_jobs)\n",
    "            except ValueError as ve:\n",
    "                continue #Ignores ValueError for wrong number of kfolds\n",
    "            \n",
    "            #Gather and Save Results\n",
    "            df_results = pd.DataFrame.from_dict(full_scores)\n",
    "            df_results['folds'] = int(i)\n",
    "            df_short = df_results.filter(regex=\"mean|std|params\")\n",
    "            df_results.to_csv(wfml.get_filepath('tune', classifier+i, True), mode='a', header=(i == folds[0]), index = False)\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"Fold {i} completed in {end_time - start:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efe626",
   "metadata": {},
   "source": [
    "## Train Method\n",
    "This method is used for training the models and display results on training dataset (as validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b2fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def train(classifier, parameters):\n",
    "        start = time.time()\n",
    "\n",
    "        #Read Training File\n",
    "        df = pd.read_csv(__class__.get_filepath('train'))\n",
    "\n",
    "        #Define Features & Target Variable\n",
    "        X = df[wfml.features]\n",
    "        y = df[wfml.target]\n",
    "\n",
    "        # Split dataset into training (80%) and testing (20%) sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        #Classifier Configuration and Training\n",
    "        if classifier == \"XGB\":\n",
    "            model = XGBClassifier(**parameters)\n",
    "        elif classifier == \"RF\":\n",
    "            model = RandomForestClassifier(**parameters)\n",
    "        else:\n",
    "            raise ValueError(\"Classifier not defined\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        #Initial test with Training dataset\n",
    "        y_predict = model.predict(X_test)\n",
    "\n",
    "        #Print Results of Initial Test\n",
    "        end_time = time.time()\n",
    "        print(\"=======================================================\")\n",
    "        print(f\"Training Results for {model.__class__.__name__}.\\nTime Elapsed: {end_time - start:.2f} seconds.\")\n",
    "        print(\"=======================================================\")\n",
    "        print(classification_report(y_test, y_predict, target_names=['no-fire', 'fire']))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        #Return Trained Classifier\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a656b",
   "metadata": {},
   "source": [
    "## Test Method\n",
    "This method is used for testing the trained models to actual data (non-weighed and in bigger volume).\n",
    "\n",
    "Here we have to handle massive records of data (31 files of approximately 500.000 records each), representing the real daily wildfire measurements of July 2020 in Greece. To handle this more effectively the model runs separately for each file and stores results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6becbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def test(model, storage):\n",
    "        start = time.time()\n",
    "\n",
    "        #Iniatite storing of Labels & Predictions (multiple due to multiple files)\n",
    "        labels = []\n",
    "        predictions = []\n",
    "        scores = []\n",
    "        \n",
    "        filepaths = __class__.get_filepaths(storage)\n",
    "        \n",
    "        #Read files & Predict with the trained model\n",
    "        msg =   \"________________________________________________\"\n",
    "        msg += f\"Test for {model.__class__.__name__} begun\"\n",
    "        msg +=  \"________________________________________________\"\n",
    "        subprocess.run(f\"echo {msg}\", shell=True) \n",
    "        for filepath in filepaths:\n",
    "            df = pd.read_csv(filepath, index_col=None, header=0)\n",
    "\n",
    "            X = df[wfml.features]\n",
    "            y = df[wfml.target]\n",
    "            \n",
    "            # Perform Predictions & Scores\n",
    "            y_predict = model.predict(X)\n",
    "            y_score = model.predict_proba(X)[:, 1]\n",
    "\n",
    "            # Gather Labels & Prediction results\n",
    "            labels.append(y)\n",
    "            predictions.append(y_predict)\n",
    "            scores.append(y_score)\n",
    "\n",
    "            # Make sure code is running :)\n",
    "            subprocess.run(f\"echo {filepath}\", shell=True) \n",
    "\n",
    "        #Merge arrays from all files of Actuals, Predictions and Scores\n",
    "        flat_labels = [item for sublist in labels for item in sublist]\n",
    "        flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "        flat_scores = [item for sublist in scores for item in sublist]\n",
    "\n",
    "        #Print Classification Report\n",
    "        end_time = time.time()\n",
    "        print(\"=======================================================\")\n",
    "        print(f\"Test Results for {model.__class__.__name__}.\\nTime Elapsed: {end_time - start:.2f} seconds.\")\n",
    "        print(\"=======================================================\")\n",
    "        print(classification_report(flat_labels, flat_predictions, target_names=['no-fire', 'fire']))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        return { 'labels' : flat_labels,\n",
    "                 'predictions' : flat_predictions,\n",
    "                 'scores' : flat_scores }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c459f1",
   "metadata": {},
   "source": [
    "## ROC Curve Method\n",
    "Creates and displays diagram for ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cfdfb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def roc_curve(model, labels, scores):\n",
    "        fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "        roc_auc = roc_auc_score(labels, scores)\n",
    "\n",
    "        # Plot ROC curve\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        # Save & Display Graph\n",
    "        plt.savefig(wfml.get_filepath('image', f'roc_{model.__class__.__name__}', True))\n",
    "        print(\"=============================\")\n",
    "        print(f\"{model.__class__.__name__}\")\n",
    "        print(\"=============================\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cafeab",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "Creates and displays diagram for Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b0f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def confusion_matrix(model, labels, predictions):\n",
    "        conf_matrix = confusion_matrix(labels, predictions)\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = ['No-Fire', 'Fire'])\n",
    "        cm_display.plot()\n",
    "\n",
    "        # Save & Display Graph\n",
    "        plt.savefig(wfml.get_filepath('image', f'cm_{model.__class__.__name__}', True))\n",
    "        print(\"=============================\")\n",
    "        print(f\"{model.__class__.__name__}\")\n",
    "        print(\"=============================\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399c98d",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Creates and displays diagram for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffb7a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def feature_importance(model):\n",
    "        #Prepare Plot\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.barh(__class__.features, model.feature_importances_, color='skyblue')\n",
    "        plt.xlabel('Gini Importance')\n",
    "        plt.title('Feature Importance - Gini Importance')\n",
    "        plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "        \n",
    "        # Save & Display Graph\n",
    "        plt.savefig(wfml.get_filepath('image', f'fi_{model.__class__.__name__}', True))\n",
    "        print(\"=============================\")\n",
    "        print(f\"{model.__class__.__name__}\")\n",
    "        print(\"=============================\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
